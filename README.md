# Crawler

Um sistema de crawler inteligente que combina raspagem de dados web com IA para an√°lise sem√¢ntica de conte√∫do.

## üìã Introdu√ß√£o

O Crawler √© uma solu√ß√£o completa para extra√ß√£o e an√°lise de conte√∫do web que integra t√©cnicas de web scraping paralelo com processamento de linguagem natural. O sistema oferece capacidades avan√ßadas de busca sem√¢ntica atrav√©s de embeddings e modelos de linguagem, permitindo n√£o apenas a coleta de dados, mas tamb√©m a compreens√£o contextual do conte√∫do extra√≠do.

## üéØ Descri√ß√£o do Problema

Na era digital atual, a necessidade de extrair e analisar grandes volumes de informa√ß√µes da web √© crescente. Os desafios incluem:

- **Escalabilidade**: Processar milhares de p√°ginas web de forma eficiente
- **An√°lise Sem√¢ntica**: Ir al√©m da simples extra√ß√£o de texto para compreender o contexto
- **Performance**: Otimizar o tempo de processamento sem comprometer a qualidade
- **Flexibilidade**: Suportar diferentes modos de opera√ß√£o conforme a necessidade

Solu√ß√µes tradicionais de web scraping s√£o limitadas por:
- Processamento sequencial lento
- Falta de capacidades de an√°lise sem√¢ntica
- Dificuldade em realizar buscas contextuais
- Aus√™ncia de armazenamento estruturado para consultas avan√ßadas


### Descri√ß√£o da Solu√ß√£o

- **üîÑ Web Scraping Paralelo**: Extra√ß√£o eficiente usando processamento paralelo com at√© 24 processos simult√¢neos
- **üß† Processamento com IA**: Utiliza√ß√£o de embeddings e LLMs para an√°lise contextual
- **üìä Banco de Dados Vetorial**: Armazenamento com ChromaDB para busca sem√¢ntica
- **üîç Busca de Palavras**: Contagem e pesquisa por termos espec√≠ficos
- **üíª Interface Terminal**: Opera√ß√£o completa via linha de comando

### Modos de Execu√ß√£o

1. **Scraping Puro**: Coleta de dados sem an√°lise sem√¢ntica
2. **Scraping + IA**: Coleta com indexa√ß√£o vetorial e consultas sem√¢nticas
3. **Scraping + Busca**: Coleta com an√°lise estat√≠stica de palavras
4. **Modo Interativo**: Interface para consultas ao banco vetorial

### Arquitetura

```
URL Base ‚Üí Scraping Paralelo ‚Üí Processamento IA ‚Üí Armazenamento Vetorial ‚Üí Consultas Sem√¢nticas
    ‚Üì           ‚Üì                     ‚Üì                    ‚Üì
Profundidade ‚Üí Processos ‚Üí Embeddings ‚Üí ChromaDB ‚Üí RAG (Retrieval-Augmented Generation)
```

### Configura√ß√µes

- **URL Base**: URL inicial para o processo de scraping
- **Profundidade M√°xima**: N√≠veis de links a seguir (1-4)
- **Processos**: N√∫mero de processos paralelos (1-24)
- **IA**: Ativa√ß√£o/desativa√ß√£o do processamento sem√¢ntico


### Tabela de Performance
![alt text](image.png)
|![alt text](image-1.png)


**Recomenda√ß√µes de Configura√ß√£o:**
- **Workloads Pequenos** (Prof. 2): 4-8 processos
- **Workloads M√©dios** (Prof. 3): 8-16 processos  
- **Workloads Grandes** (Prof. 4): 16-24 processos
- **Configura√ß√£o Equilibrada**: 12-16 processos (melhor rela√ß√£o performance/efici√™ncia)

### Depend√™ncias

```bash
pip install -r requirements.txt
```

### Principais Depend√™ncias

- `chromadb` - Banco de dados vetorial
- `urllib3` - Requisi√ß√µes HTTP
- `concurrent.futures` - Execu√ß√£o paralela
- `langchain` + `ollama` - Integra√ß√£o com LLMs
- `beautifulsoup4` - Parsing HTML

### Execu√ß√£o

```bash
python crawler.py
```

## üéØ Conclus√£o

O Crawler demonstra excelente escalabilidade e efici√™ncia no processamento paralelo de conte√∫do web. Os resultados dos benchmarks evidenciam:

### Principais Conquistas

1. **Escalabilidade Excepcional**: Speedup de at√© 15.6x com processamento paralelo
2. **Performance Otimizada**: Throughput m√°ximo de 33.58 p√°ginas/segundo
3. **Efici√™ncia Mantida**: >90% de efici√™ncia at√© 8 processos paralelos
4. **Flexibilidade Operacional**: M√∫ltiplos modos de execu√ß√£o conforme necessidade

### Impacto e Benef√≠cios

- **Redu√ß√£o de Tempo**: Processamento 15x mais r√°pido comparado ao sequencial
- **An√°lise Inteligente**: Capacidades de busca sem√¢ntica com IA
- **Versatilidade**: Suporte tanto para coleta simples quanto an√°lise complexa
- **Otimiza√ß√£o de Recursos**: Configura√ß√µes adapt√°veis ao hardware dispon√≠vel

### Limita√ß√µes Identificadas

- Diminui√ß√£o da efici√™ncia com >16 processos devido ao overhead
- Repeti√ß√£o de palavras por sobreposi√ß√£o de chunks
- Alta demanda de processamento para funcionalidades de IA

O sistema representa uma solu√ß√£o robusta e escal√°vel para extra√ß√£o e an√°lise de conte√∫do web, adequada tanto para aplica√ß√µes acad√™micas quanto comerciais que exigem recupera√ß√£o sem√¢ntica de informa√ß√µes.

---

## üë• Autores

- **Isaque Evangelista**
- **Ezio Pacheco**

*Maio de 2025*